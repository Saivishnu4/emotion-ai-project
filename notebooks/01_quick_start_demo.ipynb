{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion AI - Quick Start Demo\n",
    "\n",
    "This notebook demonstrates how to use the Emotion AI models for:\n",
    "- Emotion classification\n",
    "- Facial keypoint detection\n",
    "- Combined predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from src.models.emotion_model import EmotionClassifier\n",
    "from src.models.keypoint_model import KeypointDetector\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load emotion classifier\n",
    "emotion_model = EmotionClassifier()\n",
    "emotion_model.compile_model()\n",
    "\n",
    "# Load keypoint detector\n",
    "keypoint_model = KeypointDetector()\n",
    "keypoint_model.compile_model()\n",
    "\n",
    "print(\"âœ“ Models loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "image_path = 'path/to/your/test/image.jpg'\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Test Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Emotion Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize for emotion model\n",
    "emotion_img = cv2.resize(image, (48, 48))\n",
    "\n",
    "# Predict\n",
    "emotion_result = emotion_model.predict(emotion_img)\n",
    "\n",
    "print(f\"Predicted Emotion: {emotion_result['emotion']}\")\n",
    "print(f\"Confidence: {emotion_result['confidence']:.2%}\")\n",
    "print(\"\\nAll Probabilities:\")\n",
    "for emotion, prob in emotion_result['probabilities'].items():\n",
    "    print(f\"  {emotion}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Keypoint Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize for keypoint model\n",
    "keypoint_img = cv2.resize(image, (96, 96))\n",
    "\n",
    "# Predict\n",
    "keypoints = keypoint_model.predict(keypoint_img)\n",
    "\n",
    "print(f\"Detected {len(keypoints)} keypoints\")\n",
    "print(\"\\nKeypoint coordinates:\")\n",
    "for i, (x, y) in enumerate(keypoints):\n",
    "    print(f\"  Keypoint {i+1}: ({x:.2f}, {y:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot keypoints on image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(keypoint_img, cmap='gray')\n",
    "\n",
    "# Draw keypoints\n",
    "for x, y in keypoints:\n",
    "    plt.plot(x, y, 'ro', markersize=8)\n",
    "\n",
    "plt.title(f'Detected Emotion: {emotion_result[\"emotion\"]} ({emotion_result[\"confidence\"]:.2%})')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Processing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process multiple images\n",
    "import glob\n",
    "\n",
    "image_paths = glob.glob('path/to/images/*.jpg')\n",
    "\n",
    "results = []\n",
    "for img_path in image_paths[:5]:  # Process first 5 images\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_resized = cv2.resize(img, (48, 48))\n",
    "    \n",
    "    result = emotion_model.predict(img_resized)\n",
    "    results.append({\n",
    "        'path': img_path,\n",
    "        'emotion': result['emotion'],\n",
    "        'confidence': result['confidence']\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
